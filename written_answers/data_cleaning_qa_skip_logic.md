# Data Issues
1. **Variable date formats** (e.g. "2025/10" vs. "2025-10"). This was fixed implicitly in `_normalize_date()` in `_validate_row()` in `validate.py`, validated in data validation schema, and then logged to the `qa_flags` node in `validated_data/validated_rows_{latest_data_month}_{run_id_datetime}.json`. _This did not prevent publication._
   
2. **Variable state name formats** (e.g. Calif. vs. California). This was fixed implicity in `_validate_row()` in `validate.py` with the helper `STATE` static shared utility reference data in `states.py`. It is also logged to the `qa_flags` node in `validated_data/validated_rows_{latest_data_month}_{run_id_datetime}.json`. _This did not prevent publication._
   
3. **Missing values** in `unemployment_rate_prev_month`. This was logged to the `qa_flags` node in `validated_data/validated_rows_{latest_data_month}_{run_id_datetime}.json`. A note on logic: in `run_clean()` in `clean.py` the state data is pivoted to long format which will produce inherent duplicate combinations of `state` and `date` due to the `unemployment_rate`	and `unemployment_rate_prev_month` values. The data is sorted ascending in this cleaning state so the more recent month's `unemployment_rate_prev_month` value is used instead of a state/month combo's `unemployment_rate`. This logic is based on the assumption that the `unemployment_rate_prev_month` is going to have the more recently processed data for a given state/month (potentially after revisions or error corrections). This logic can be changed to preference the `unemployment_rate` field. _This did not prevent publication._ 
   1. ***However***, if a state/date combo's `unemployment_rate` and `unemployment_rate_prev_month` values were _different_ for a given month (such as Colorado for 2025-10 and Rhode Island for 2025-11) this prevented data for this state/date combo from being published (`"is_publishable": false` in `validated_data/validated_rows_{latest_data_month}_{run_id_datetime}.json`) to the `clean_data/clean_data.jsonl` file.
   
4. **Conditions that triggered no publication**: 1. The negative `unemployment_rate` data for Colorado on 2025-10 which was caught in `_validate_row()` in `validate.py` via the `IMPLAUSIBLE_RATE_LOWER_BOUND` constant and propegates to `"is_publishable":` in `validated_data/validated_rows_{latest_data_month}_{run_id_datetime}.json`, `"implausible_rate"` in `.pipeline_state/validate_output.json`, and implicitly via the difference between the `"rows_validated":` and `"rows_publishable":` values in `.pipeline_state/run_manifest.json`. 2. The mismatch between Rhode Island's 2025-11 data which was caught by `_check_rate_conflicts()` in `validate.py`. And shows up in `"rate_conflict"` in `.pipeline_state/validate_output.json` (as well as a warning in `"rate_unusually_high":` via the `RATE_WARNING_THRESHOLD` constant in `validate.py based on previous recessionary high values).
   1. Again, values both 2025-10 data for Colorado and 2025-11 data for Rhode Island end up in the `clean_data.json` based on the `unemployment_rate_prev_month` values for the subsequent months for those state/date combos passing validation. So that data would get published.
    
5. **Duplicate rows**: There were 5 duplicate rows, one each for Hawaii, Illinois, Ohio, Wyoming, and Texas. Because they were complete duplicates they did not throw errors and were logged in `"rows_deduped_input":` in `.pipeline_state/clean_output.json`. This logic could also be changed if desired. 

# Skip, Alert, and Fail Conditions
1. If more than 40% of states (configurable via `PUBLISH_GATE_THRESHOLD` threshold in `validate.py`) have all rows unpublishable, error is thrown in the pipeline
2. Per-state/month combo warnings are logged and captured in `qa_flags` but do not stop execution. The flag propagates into `wordsmith_payload.json` for editorial review.
3. The `clean_data/clean_data.json` file is add-only and has both `injest_run` and `source_row_id` metadata to handle updates to corrected or revised future data for a state/month. Data for the `dw_viz_data/` CSVs and the `wordsmith_json_payload/` JSON are sourced from this file and use the _most recently injested_ (via `injest_run`) figure for each state/month.
